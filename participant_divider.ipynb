{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating participants into groups\n",
    "\n",
    "Simple script that builds a sheet in an excel file.\n",
    "\n",
    "## Usage\n",
    "\n",
    "In a camp participant's spreadsheet, this script takes the paying and confirmed participants and separates them into groups by age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, read the files in the `source` folder — the script gets the first `xlsx` it finds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting script...\n"
     ]
    }
   ],
   "source": [
    "input(\"Press any key to start...\")\n",
    "print(\"Starting script...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file_folder = Path(\"./source\")\n",
    "\n",
    "\n",
    "def find_first_xlsx():\n",
    "    for filename in file_folder.glob(\"*.xlsx\"):\n",
    "        if \"xlsx\" in str(filename):\n",
    "            return Path(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns the sheet into a dataframe and sets the phone as string (to avoid confusion with numbers and zeroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFound file source/Acampa  2025 - VOCARE (CENTRAL).xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = find_first_xlsx()\n",
    "print(f\"\\tFound file {path}\")\n",
    "\n",
    "df = pd.read_excel(\n",
    "    path,\n",
    "    sheet_name=\"LISTA DE PAGANTES (FINANCEIRA)\",\n",
    "    header=9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns `Desistente` and `Pago` into booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFiltering out dropouts, non-paid, and team members...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tFiltering out dropouts, non-paid, and team members...\")\n",
    "\n",
    "df[\"Desistente\"] = df[\"Desistente\"] != \"NÃO\"\n",
    "df[\"Pago?\"] = df[\"Pago?\"] == \"PAGANTE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters out team members — leaving only participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Será Acampante ou Equipe?\"] == \"Sou participante (acampante)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters out non-paying and dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Pago?\"]]\n",
    "df = df[~df[\"Desistente\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRemoving unused columns...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tRemoving unused columns...\")\n",
    "\n",
    "df.drop(\n",
    "    columns=[\n",
    "        'Telefone para contato (Ex: 11XXXXXXXXX sem traço \"-\" e sem pontos \".\")',\n",
    "        \"Pago?\",\n",
    "        \"Desistente\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order by age and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values([\"Idade\"], ascending=[True], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new column and add group using **round-robyn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSeparating into 6 groups...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tSeparating into 6 groups...\")\n",
    "\n",
    "df[\"Grupo\"] = 0\n",
    "\n",
    "for i, index in enumerate(df.index):\n",
    "    df.loc[index, \"Grupo\"] = (i % 6) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare new filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWriting xlsx file...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(\"\\tWriting xlsx file...\")\n",
    "\n",
    "pattern = r\"(?<=/)(.*?)(?=\\.xlsx)\"\n",
    "match = re.search(pattern, str(path))\n",
    "\n",
    "if not match:\n",
    "    raise Exception('Wait, is there an xlsx file inside \"source\" folder?')\n",
    "\n",
    "old_name = match.group(0)\n",
    "new_path = re.sub(pattern, f\"{old_name} - COM GRUPOS\", str(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write new excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "workbook = openpyxl.load_workbook(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a sheet with every person and their groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating unified sheet...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tCreating unified sheet...\")\n",
    "\n",
    "# FIRST: a unified sheet\n",
    "unified_sheet_name = \"Grupos (todos)\"\n",
    "if unified_sheet_name in workbook.sheetnames:\n",
    "    unified_sheet = workbook[unified_sheet_name]\n",
    "else:\n",
    "    unified_sheet = workbook.create_sheet(unified_sheet_name)\n",
    "\n",
    "# Clear sheet\n",
    "unified_sheet.delete_rows(1, unified_sheet.max_row)\n",
    "\n",
    "row_index = 1\n",
    "\n",
    "# Write the headers\n",
    "for c, col_name in enumerate(df.columns):\n",
    "    cell = unified_sheet.cell(row=1, column=c + 1)\n",
    "    cell.value = col_name\n",
    "\n",
    "# Write rows\n",
    "for r in range(df.shape[0]):\n",
    "    for c in range(df.shape[1]):\n",
    "        cell = unified_sheet.cell(row=r + 2, column=c + 1)\n",
    "        cell.value = df.iloc[r, c]\n",
    "\n",
    "# Apply AutoFilter\n",
    "start_column = 1  # Column A (1)\n",
    "end_column = len(df.columns)  # Number of columns\n",
    "end_row = df.shape[0] + 1  # Last row including header\n",
    "\n",
    "filter_range = f\"A1:{chr(64 + end_column)}{end_row}\"\n",
    "unified_sheet.auto_filter.ref = filter_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a sheet with separated groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating separated sheet...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tCreating separated sheet...\")\n",
    "\n",
    "# THEN, A SEPARATED SHEET\n",
    "separated_sheet_name = \"Grupos (separado)\"\n",
    "\n",
    "if separated_sheet_name in workbook.sheetnames:\n",
    "    separated_sheet = workbook[separated_sheet_name]\n",
    "else:\n",
    "    separated_sheet = workbook.create_sheet(separated_sheet_name)\n",
    "\n",
    "# Clear sheet\n",
    "separated_sheet.delete_rows(1, separated_sheet.max_row)\n",
    "\n",
    "dfs = {group: group_df for group, group_df in df.groupby(\"Grupo\")}\n",
    "\n",
    "row_index = 1\n",
    "\n",
    "for group, group_df in dfs.items():\n",
    "    separated_sheet.cell(row=row_index, column=1, value=f\"Grupo {group}\")\n",
    "    row_index += 2  # Move down 2 rows, one for empty space\n",
    "\n",
    "    # Write headers\n",
    "    for c, col_name in enumerate(group_df.columns):\n",
    "        cell = separated_sheet.cell(row=row_index, column=c + 1)\n",
    "        cell.value = col_name\n",
    "\n",
    "    row_index += 1  # Move to the next row for data\n",
    "\n",
    "    # Write data\n",
    "    for r in range(group_df.shape[0]):\n",
    "        for c in range(group_df.shape[1]):\n",
    "            cell = separated_sheet.cell(row=row_index + r, column=c + 1)\n",
    "            cell.value = group_df.iloc[r, c]\n",
    "\n",
    "    row_index += group_df.shape[0] + 2  # Move down after each group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new workbook!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source/Acampa  2025 - VOCARE (CENTRAL) - COM GRUPOS.xlsx file written successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workbook.save(new_path)\n",
    "print(f\"{new_path} file written successfully.\")\n",
    "input(\"Press any key to end...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camp-participant-divider-tiom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
